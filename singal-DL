import os
os.environ["CUDA_VISIBLE_DEVICES"]="1"
import cv2
import pickle
import numpy as np
import pandas as pd
import shutil
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import random
import joblib

import tensorflow as tf
from tensorflow import expand_dims
from tensorflow.keras.applications import InceptionResNetV2, VGG16, EfficientNetB3
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import Dense, Dropout, concatenate, GlobalAveragePooling2D, Reshape, MultiHeadAttention
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from Confidence_interval import bootstrap_auc

import tensorflow.keras.models


# 图像数据读取函数
def get_images(path, size=(224,224,3), normalized=False):
    """
    获得模型学习所需要的数据；
    其中图像格式(num_images, weight, height)
    标注格式(num_images, weight, height)，像素值为0/1
    注：训练数据目录结构如下
    path/
            0/   - neg
            1/   - pos
    """

    files_neg = os.listdir(os.path.join(path, 'negative'))
    files_neg.sort()

    files_pos = os.listdir(os.path.join(path, 'positive'))
    files_pos.sort()

    images = np.zeros([len(files_neg)+len(files_pos),size[0],size[1],size[2]])
    y = np.zeros([len(files_neg)+len(files_pos)])
    for i, file in enumerate(files_neg):
        patient_file = os.path.join(path, 'negative', file)
        for f in os.listdir(patient_file):
            img = cv2.imread(os.path.join(patient_file, f))
            # print(os.path.join(patient_file, f))
            img = cv2.resize(img, (size[0], size[1]), cv2.INTER_AREA)
            if normalized:
                images[i] = img/255
            else:
                images[i] = img
            y[i]=0

    for i, file in enumerate(files_pos):
        patient_file = os.path.join(path, 'positive', file)
        for f in os.listdir(patient_file):
            img = cv2.imread(os.path.join(patient_file, f))
            img = cv2.resize(img, (size[0], size[1]), cv2.INTER_AREA)
            if normalized:
                images[i+len(files_neg)] = img/255
            else:
                images[i+len(files_neg)] = img
            y[i+len(files_neg)]=1

    return images,y

# cnn模型特征输入分支
XSIZE,YSIZE,ZSIZE = 224,224,3

# transfer learning setting
#   0 - no initial weights
#   1 - imagenet pretrained weights
#   2 - transfer learning weights from SMC-net
#
transfer_learning_style = 2  

# cnn-image input
if transfer_learning_style==0:
    clf_cnn = EfficientNetB3(include_top=False,input_shape=(XSIZE,YSIZE,ZSIZE))
elif transfer_learning_style==1:
    clf_cnn = EfficientNetB3(include_top=False, weights='imagenet', input_shape=(XSIZE, YSIZE, ZSIZE))
else:    
    clf_cnn = EfficientNetB3(include_top=False,input_shape=(XSIZE,YSIZE,ZSIZE))
    model = GlobalAveragePooling2D(name='GlobalAverage')(clf_cnn.output)
    model = Dense(256, activation='relu')(model)
    model = Dropout(0.5)(model)
    model = Dense(64, activation='relu')(model)
    model = Dense(2, activation='softmax')(model)
    model_efn_sp = Model(clf_cnn.input, model)
    cnn_weight_file = "breast/deep_learning/checkpoint/saved_models/EfficientNetB3-cnn02.193.h5"
    model_efn_sp.load_weights(cnn_weight_file)
    print(model_efn_sp.summary())

    # last_conv_layer_name = "top_activation"
    # clf_cnn = tf.keras.models.Model(
    #     [model_efn_sp.inputs], [model_efn_sp.get_layer(last_conv_layer_name).output]
    # )
    # print(clf_cnn.summary())

    # model_cnn = Dense(102, activation='relu',name='reshape_feature_vector')(clf_cnn.output)
    # model_cnn = GlobalAveragePooling2D(name='GlobalAverage2D_cnn')(clf_cnn.output)
    # model_cnn = Reshape((1,-1),name="reshape_cnn_vector")(model_cnn)
#     cnn_efn = Model(inputs=model_efn_sp.input, outputs=model_efn_sp.output, name="model_cnn")
#     for layer in cnn_efn.layers:
#         layer.trainable = True
#         layer._name = layer._name + str("_cnn")
#     print(cnn_efn.summary())
# exit(0)

# 图像数据
x_train_cnn, y_train_cnn = get_images("breast/jicheng/dataset/dpset/02030405071516")
x_test1_cnn, y_test1_cnn = get_images("breast/jicheng/dataset/dpset/11")
x_test2_cnn, y_test2_cnn = get_images("breast/jicheng/dataset/dpset/12")


# 用于训练的数据大小
print("用于训练的图像数据为", x_train_cnn.shape)
print("用于测试的图像数据为", x_test1_cnn.shape)
print("用于测试的图像数据为", x_test2_cnn.shape)

# #############################################################
# x_train_cnn_features = cnn_efn.predict(x_train_cnn)
# x_train_cnn_features = pd.DataFrame(x_train_cnn_features)
# print(x_train_cnn_features)
# y_train_cnn = pd.DataFrame(y_train_cnn)
# y_train_cnn.columns=['labels']
# train_cnn_features = pd.concat([y_train_cnn, x_train_cnn_features], axis = 1)
# print(train_cnn_features)

# x_test1_cnn_features = cnn_efn.predict(x_test1_cnn)
# x_test1_cnn_features = pd.DataFrame(x_test1_cnn_features)
# print(x_test1_cnn_features)
# y_test1_cnn = pd.DataFrame(y_test1_cnn)
# y_test1_cnn.columns=['labels']
# test1_cnn_features = pd.concat([y_test1_cnn, x_test1_cnn_features], axis = 1)
# print(test1_cnn_features)

# x_test2_cnn_features = cnn_efn.predict(x_test2_cnn)
# x_test2_cnn_features = pd.DataFrame(x_test2_cnn_features)
# print(x_test2_cnn_features)
# y_test2_cnn = pd.DataFrame(y_test2_cnn)
# y_test2_cnn.columns=['labels']
# test2_cnn_features = pd.concat([y_test2_cnn, x_test2_cnn_features], axis = 1)
# print(test2_cnn_features)

# cnn_train_path = r'breast/jicheng/dataset/cnn_02030405071516_all.csv'
# cnn_test1_path = r'breast/jicheng/dataset/cnn_11_all.csv'
# cnn_test2_path = r'breast/jicheng/dataset/cnn_12_all.csv'

# train_cnn_features.to_csv(cnn_train_path)
# test1_cnn_features.to_csv(cnn_test1_path)
# test2_cnn_features.to_csv(cnn_test2_path)

# #####################################################################

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
def cm(y_test,y_predicted,name):
    classes = [0,1]
    cm = confusion_matrix(y_test,y_predicted, labels=[0,1])
    print(cm)
    TP = cm[1, 1]
    TN = cm[0, 0]
    FP = cm[0, 1]
    FN = cm[1, 0]
    # 通过混淆矩阵计算每个评估指标的值
    print('Accuracy:', (TP + TN) / float(TP + TN + FP + FN))
    print('Sensitivity:', TP / float(TP + FN))
    print('Specificity:', TN / float(TN + FP))
    print('PPV:',TP / float(TP + FP))
    print('NPV:',TN / float(TN + FN))
    print('Recall:',TP / float(TP + FN))
    print('Precision:',TP / float(TP + FP))
    P = TP / float(TP + FP)
    R = TP / float(TP + FN)
    print('F1-score:',(2*P*R)/(P+R))
    plt.figure(figsize=(5,5))
    plt.imshow(cm, cmap=plt.cm.Greens)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation = 0)
    plt.yticks(tick_marks, classes)
    thresh = cm.max() / 2.
    for i in range(len(cm)):
        for j in range(len(cm)):
            plt.annotate(cm[j, i], xy=(i, j), horizontalalignment='center', verticalalignment='center', 
                            fontsize=16,color = 'white' if cm[i, j] > thresh else 'black')
    plt.ylabel('True label', fontsize=16)
    plt.xlabel('Predicted label', fontsize=16)
    plt.title('Confusion matrix : ' + name,fontsize=16)
    plt.savefig('breast/jicheng/pictures/cm_' + name + '.jpg')
    plt.show()

#roc曲线
from sklearn.metrics import roc_curve, auc  ###计算roc和auc
from Confidence_interval import bootstrap_auc
def roc(y_test,y_score,name):

    fpr,tpr,threshold = roc_curve(y_test, y_score) ###计算真正率和假正率
    # print(threshold)
    roc_auc = auc(fpr,tpr) ###计算auc的值
    print('AUC : {}'.format(roc_auc))

    plt.figure(figsize=(5,5))
    plt.plot(fpr, tpr, color='darkorange', linewidth=2, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率为横坐标，真正率为纵坐标做曲线
    plt.plot([0, 1], [0, 1], color='navy', linewidth=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate', fontsize = 16)
    plt.ylabel('True Positive Rate', fontsize = 16)
    plt.title('Receiver operating characteristic : '+ name,fontsize = 16)
    plt.legend(loc="lower right", fontsize = 12)
    plt.savefig('breast/jicheng/pictures/roc_' + name + '.jpg')
    plt.show()

y_train_predict_cnn = model_efn_sp.predict(x_train_cnn)
y_test1_predict_cnn = model_efn_sp.predict(x_test1_cnn)
y_test2_predict_cnn = model_efn_sp.predict(x_test2_cnn)

y_train_predict_classindex_cnn = np.argmax(y_train_predict_cnn,axis=1)#返回一个numpy数组中最大值的索引值,axis = 1: （行比较输出）
y_test1_predict_classindex_cnn = np.argmax(y_test1_predict_cnn,axis=1)
y_test2_predict_classindex_cnn = np.argmax(y_test2_predict_cnn,axis=1)


flag_test1_cnn = 0
for i in range(len(y_test1_predict_classindex_cnn)):
    if(y_test1_predict_classindex_cnn[i] == int(y_test1_cnn[i])):
        flag_test1_cnn += 1
    else:
        continue
print("cnn test1 accuracy:", flag_test1_cnn/(len(y_test1_cnn)))

flag_test2_cnn = 0
for i in range(len(y_test2_predict_classindex_cnn)):
    if(y_test2_predict_classindex_cnn[i] == y_test2_cnn[i]):
        flag_test2_cnn += 1
    else:
        continue
print("cnn test2 accuracy:", flag_test2_cnn/(len(y_test2_cnn)))

flag_train_cnn = 0
for i in range(len(y_train_predict_classindex_cnn)):
    if(y_train_predict_classindex_cnn[i] == y_train_cnn[i]):
        flag_train_cnn += 1
    else:
        continue
print("cnn train accuracy:", flag_train_cnn/(len(y_train_cnn)))

print("*******************************")

precision_test1 = precision_score(y_test1_cnn,y_test1_predict_classindex_cnn, average='binary')
recall_test1 = recall_score(y_test1_cnn, y_test1_predict_classindex_cnn, average='binary')
f1_test1 = f1_score(y_test1_cnn, y_test1_predict_classindex_cnn, average='binary')
acc_test1 = accuracy_score(y_test1_cnn, y_test1_predict_classindex_cnn)
auc_CI_test1 = bootstrap_auc(y_test1_cnn, y_test1_predict_cnn[:,1],len(y_test1_cnn))

precision_test2 = precision_score(y_test2_cnn,y_test2_predict_classindex_cnn, average='binary')
recall_test2 = recall_score(y_test2_cnn, y_test2_predict_classindex_cnn, average='binary')
f1_test2 = f1_score(y_test2_cnn, y_test2_predict_classindex_cnn, average='binary')
acc_test2 = accuracy_score(y_test2_cnn, y_test2_predict_classindex_cnn)
auc_CI_test2 = bootstrap_auc(y_test2_cnn, y_test2_predict_cnn[:,1],len(y_test2_cnn))

precision_train = precision_score(y_train_cnn,y_train_predict_classindex_cnn, average='binary')
recall_train = recall_score(y_train_cnn, y_train_predict_classindex_cnn, average='binary')
f1_train = f1_score(y_train_cnn, y_train_predict_classindex_cnn, average='binary')
acc_train = accuracy_score(y_train_cnn, y_train_predict_classindex_cnn)
auc_CI_train = bootstrap_auc(y_train_cnn, y_train_predict_cnn[:,1],len(y_train_cnn))


# print('the train 精准值 is :', precision_train)
# print('the train 召回率 is :', recall_train)
# print('the train F1 is :', f1_train)
# print("the train 准确率 is :", acc_train)
cm(y_train_cnn,y_train_predict_classindex_cnn,'MModel_cnn_02030405071516')
roc(y_train_cnn,y_train_predict_cnn[:,1],'MModel_cnn_02030405071516')
print("the train 置信区间 is :",auc_CI_train)
print("********************************************")
# print('the test1 精准值 is :', precision_test1)
# print('the test1 召回率 is :', recall_test1)
# print('the test1 F1 is :', f1_test1)
# print("the test1 准确率 is :", acc_test1)
cm(y_test1_cnn,y_test1_predict_classindex_cnn,'MModel_cnn_11')
roc(y_test1_cnn,y_test1_predict_cnn[:,1],'MModel_cnn_11')
print("the test1 置信区间 is :",auc_CI_test1)
print("********************************************")
# print('the test2 精准值 is :', precision_test2)
# print('the test2 召回率 is :', recall_test2)
# print('the test2 F1 is :', f1_test2)
# print("the test2 准确率 is :", acc_test2)
cm(y_test2_cnn,y_test2_predict_classindex_cnn,'MModel_cnn_12')
roc(y_test2_cnn,y_test2_predict_cnn[:,1],'MModel_cnn_12')
print("the test2 置信区间 is :",auc_CI_test2)
